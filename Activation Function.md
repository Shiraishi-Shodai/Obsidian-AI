

# Activation Function

created: 2025-02-05 00:59
tags: #DeepLearning

## Feeling Notes
---
- 
## References
---
- 

#### 活性化関数
---
中間層、出力層の入力から出力への変換を行う関数
- ネットワークに非線形な性質を持たせるために使用する
- 活性化関数の種類によって学習回数なども変わる
- 非線形な関数ならなんでも良いわけではない
- 線形関数は入れ子にすると1次関数になるので使わない。層を深くする意味がなくなる
- ReLUは勾配消失も勾配爆発も起きにくい