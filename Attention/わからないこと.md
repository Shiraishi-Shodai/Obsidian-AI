---
tags:
  - Attention
  - Transformer
created:
  - 2025-08-23 23:29
---


## Feeling Notes
---
- 
## Literature Notes
---
- 
## References
---
- 

# わからないこと
---

- [x]  Attentionってようは何？
- [ ]  AttentionとTransformerの違いは？
- [ ]  AttentionとRNNの違いは？
- [x]  Attentionってなんで Q/K/V の3つに分ける必要があるの？
- [x]  QKVって何？
- [ ]  Attention(Q, K, V)の数式って何を表しているの？
	- [ ] Attention(Q, K, V)の数式でdkでスケーリングするのはなぜ？
	- [ ] QKVはどのようにベクトル化している？
- [ ] 単語のベクトル化ってどうやってやるの？
	- [x] ベクトルって何？
		- [ ] ベクトルの内積とは？
- [x] 単語の分散表現って何？
	- [x] 共起とは？
	- [ ] なぜコサイン類似度で単語の類似度を計れるの？
- [x] コンピュータに単語を理解させる方法とは？